# Neural-Machine-Translation-using-Transformer
The project focuses on robust neural machine translation (NMT) for English and Indian languages using Seq2Seq and Transformer architectures. The Samanantar benchmark dataset is used, with experimentation involving Transformers and hyperparameter optimization. The project navigates resource constraints, influencing model choices and training times.
